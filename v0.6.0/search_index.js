var documenterSearchIndex = {"docs":
[{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"EditURL = \"scheme.jl\"","category":"page"},{"location":"scheme/#Example:-Parsing-Scheme","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"","category":"section"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"Here we prepare a small parser for a very simple Scheme-like language.","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"The main features of the parser include:","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"handling whitespace\nparsing number-containing identifiers and numbers while avoiding ambiguities using not_followed_by\nerror recovery by manually traversing the memo table","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"We choose not to implement any of the Scheme data types except numbers and identifiers; also all top-level expressions must be parenthesized \"command\" S-expressions.","category":"page"},{"location":"scheme/#Implementing-the-grammar","page":"Example: Parsing Scheme","title":"Implementing the grammar","text":"","category":"section"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"import PikaParser as P\n\nrules = Dict(\n    :letter => P.satisfy(isletter),\n    :digit => P.satisfy(isdigit),\n    :ident => P.tie(\n        P.seq(\n            P.seq(:letter),\n            P.many(:inIdent => P.first(:letter, :digit, P.token('-'))),\n            P.not_followed_by(:inIdent),\n        ),\n    ),\n    :number => P.seq(P.some(:digit), P.not_followed_by(:inIdent)),\n    :ws => P.many(P.satisfy(isspace)),\n    :popen => P.seq(P.token('('), :ws),\n    :pclose => P.seq(P.token(')'), :ws),\n    :sexpr => P.seq(:popen, :insexpr => P.many(:scheme), :pclose),\n    :scheme => P.seq(:basic => P.first(:number, :ident, :sexpr), :ws),\n    :top => P.seq(:ws, :sexpr), #support leading blanks\n);\nnothing #hide","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"Notice that the rules \"clean\" the space characters after each sensible token is matched, except for :top that is able to clean up the leading spaces.  This way prevents unnecessary checking (and redundant matching) of the tokens, and buildup of uninteresting entries in the memo table.","category":"page"},{"location":"scheme/#Parsing-input","page":"Example: Parsing Scheme","title":"Parsing input","text":"","category":"section"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"Let's test the grammar on a piece of source code that contains lots of whitespace and some errors.","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"p = P.parse(\n    P.make_grammar([:top], P.flatten(rules, Char)),\n    \"\"\"\n(plus 1 2 3)\n(minus 1 2(plus 3 2)  ) woohoo extra parenthesis here )\n(complex\n  id3nt1f13r5 αβγδ भरत kůň)\n(invalid 1d3n7)\n(something\n  1\n  2\n  valid)\n(straight (out (missing(parenthesis error))\n(apply (make-function) (make-data))\n\"\"\",\n);\nnothing #hide","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"Prepare a folding function:","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"fold_scheme(m, p, s) =\n    m.rule == :number ? parse(Int, m.view) :\n    m.rule == :ident ? Symbol(m.view) :\n    m.rule == :insexpr ? Expr(:call, :S, s...) :\n    m.rule == :sexpr ? s[2] : m.rule == :top ? s[2] : length(s) > 0 ? s[1] : nothing;\nnothing #hide","category":"page"},{"location":"scheme/#Recovering-from-errors-and-showing-partial-parses","page":"Example: Parsing Scheme","title":"Recovering from errors and showing partial parses","text":"","category":"section"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"We can run through all top matches, tracking the position where we would expect the next match:","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"next_pos = 1\nwhile next_pos <= lastindex(p.input)\n    global next_pos\n    pos = next_pos\n    mid = 0\n    while pos <= lastindex(p.input) # try to find a match\n        mid = P.find_match_at!(p, :top, pos)\n        mid != 0 && break\n        pos = nextind(p.input, pos)\n    end\n    pos > next_pos && # if we skipped something, report it\n        println(\n            \"Got problems understanding this: $(p.input[next_pos:prevind(p.input, pos)])\",\n        )\n    if mid == 0\n        break # if we skipped all the way to the end, quit\n    else # we have an actual match, print it.\n        value = P.traverse_match(p, mid, fold = fold_scheme)\n        println(\"Got a good value: $value\")\n        m = p.matches[mid] # skip the whole match and continue\n        next_pos = nextind(p.input, m.last)\n    end\nend","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"We can see that the unparseable parts of input were correctly skipped, while the sensible parts were interpreted as expressions. The chosen error recovery method might not be optimal in the case of missing parentheses – as an improvement, one might choose to utilize another grammar rule to find a good part of input to discard (e.g., everything to the end of the line).","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"","category":"page"},{"location":"scheme/","page":"Example: Parsing Scheme","title":"Example: Parsing Scheme","text":"This page was generated using Literate.jl.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"EditURL = \"scheme_lex.jl\"","category":"page"},{"location":"scheme_lex/#Example:-Faster-parsing-with-lexers","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"","category":"section"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"One disadvantage of pika-style parsers is the large amount of redundant intermediate matches that are produced in the right-to-left parsing process. These generally pollute the match table and cause inefficiency.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"PikaParser supports greedily pre-lexing the parser input using the terminals in the grammar, which allows you to produce much more precise terminal matches, thus also more compact match table, and, in result, much faster and more robust parser.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"In this example, we simply rewrite the Scheme grammar from the Scheme tutorial to use PikaParser.scan (which allows you to match many interesting kinds of tokens quickly) and then PikaParser.parse_lex (which runs the greedy lexing and uses the result for more efficient parsing).","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"As the main change, we removed the \"simple\" matches of :digit and :letter from the grammar, and replaced them with manual matchers of whole tokens.","category":"page"},{"location":"scheme_lex/#Writing-scanners","page":"Example: Faster parsing with lexers","title":"Writing scanners","text":"","category":"section"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"First, let's make a very useful helper function that lets us convert any Char-matching function into a scanner. This neatens the grammar code later.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"When constructing the scanner functions, remember that it is important to use the overloaded indexing functions (nextind, prevind, firstindex, lastindex) instead of manually computing the integer indexes. Consider what happens with Unicode strings if you try to get an index like \"kůň\"[3]! Compute indexes manually only if you are perfectly certain that the input indexing is flat.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"takewhile1(f) = (input) -> begin\n    isempty(input) && return 0\n    for i in eachindex(input)\n        if !f(input[i])\n            return prevind(input, i)\n        end\n    end\n    return lastindex(input)\nend;\nnothing #hide","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"The situation for matching :ident is a little more complicated – we need a different match on the first letter and there are extra characters to think about. So we just make a specialized function for that:","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"function take_ident(input)\n    isempty(input) && return 0\n    i = firstindex(input)\n    isletter(input[i]) || return 0\n    i = nextind(input, i)\n    while i <= lastindex(input)\n        c = input[i]\n        if !(isletter(c) || isdigit(c) || c == '-')\n            return prevind(input, i)\n        end\n        i = nextind(input, i)\n    end\n    return lastindex(input)\nend;\nnothing #hide","category":"page"},{"location":"scheme_lex/#Using-scanners-in-a-grammar","page":"Example: Faster parsing with lexers","title":"Using scanners in a grammar","text":"","category":"section"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"The grammar becomes slightly simpler than in the original version:","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"import PikaParser as P\n\nrules = Dict(\n    :ws => P.first(:spaces => P.scan(takewhile1(isspace)), P.epsilon),\n    :popen => P.seq(P.token('('), :ws),\n    :pclose => P.seq(P.token(')'), :ws),\n    :sexpr => P.seq(:popen, :insexpr => P.many(:scheme), :pclose),\n    :scheme => P.seq(\n        :basic => P.first(\n            :number => P.seq(P.scan(takewhile1(isdigit)), P.not_followed_by(:ident)),\n            :ident => P.scan(take_ident),\n            :sexpr,\n        ),\n        :ws,\n    ),\n    :top => P.seq(:ws, :sexpr), #support leading blanks\n);\nnothing #hide","category":"page"},{"location":"scheme_lex/#Using-the-scanners-for-lexing-the-input","page":"Example: Faster parsing with lexers","title":"Using the scanners for lexing the input","text":"","category":"section"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"Let's try the lexing on the same input as in the Scheme example:","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"input = \"\"\"\n(plus 1 2 3)\n(minus 1 2(plus 3 2)  ) woohoo extra parenthesis here )\n(complex\n  id3nt1f13r5 αβγδ भरत kůň)\n(invalid 1d3n7)\n(something\n  1\n  2\n  valid)\n(straight (out (missing(parenthesis error))\n(apply (make-function) (make-data))\n\"\"\";\ngrammar = P.make_grammar([:top], P.flatten(rules, Char));\n\nP.lex(grammar, input)","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"The result is a vector of possible terminals that can be matched at given input positions. As a minor victory, you may see that no terminals are matched inside the initial plus token.","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"Now, the lexed input could be used via the argument fast_match of PikaParser.parse, but usually it is much simpler to have the combined function PikaParser.parse_lex do everything:","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"p = P.parse_lex(grammar, input);\nnothing #hide","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"The rest is now essentially same as with the previous Scheme example:","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"fold_scheme(m, p, s) =\n    m.rule == :number ? parse(Int, m.view) :\n    m.rule == :ident ? Symbol(m.view) :\n    m.rule == :insexpr ? Expr(:call, :S, s...) :\n    m.rule == :sexpr ? s[2] : m.rule == :top ? s[2] : length(s) > 0 ? s[1] : nothing;\n\nnext_pos = 1\nwhile next_pos <= lastindex(p.input)\n    global next_pos\n    pos = next_pos\n    mid = 0\n    while pos <= lastindex(p.input) # try to find a match\n        mid = P.find_match_at!(p, :top, pos)\n        mid != 0 && break\n        pos = nextind(p.input, pos)\n    end\n    pos > next_pos && # if we skipped something, report it\n        println(\"Problems with: $(p.input[next_pos:prevind(p.input, pos)])\")\n    if mid == 0\n        break # if we skipped all the way to the end, quit\n    else # we have an actual match, print it.\n        value = P.traverse_match(p, mid, fold = fold_scheme)\n        println(\"Parsed OK: $value\")\n        m = p.matches[mid] # skip the whole match and continue\n        next_pos = nextind(p.input, m.last)\n    end\nend","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"","category":"page"},{"location":"scheme_lex/","page":"Example: Faster parsing with lexers","title":"Example: Faster parsing with lexers","text":"This page was generated using Literate.jl.","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"EditURL = \"json.jl\"","category":"page"},{"location":"json/#Example:-Parsing-JSON","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"","category":"section"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"Here we prepare a parser of a very small subset of JSON.","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"The main features of the parser include:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"handling sequences with separators\nhandling string escapes\nbuilding native Julia data objects using a dictionary of handlers","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"The simplifications that we choose not to handle are the following:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"we do not support space between tokens (you can pipe your json through jq -c . to remove unnecessary spaces)\nsupport for numbers is very ad-hoc, Float64-only\nthe escape sequences allowed in strings are rather incomplete","category":"page"},{"location":"json/#Preparing-the-grammar","page":"Example: Parsing JSON","title":"Preparing the grammar","text":"","category":"section"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"import PikaParser as P\n\nrules = Dict(\n    :t => P.tokens(\"true\"),\n    :f => P.tokens(\"false\"),\n    :null => P.tokens(\"null\"),\n    :digit => P.satisfy(isdigit),\n    :number => P.seq(\n        P.first(P.token('-'), P.epsilon),\n        P.some(:digit),\n        P.first(P.seq(P.token('.'), P.many(:digit)), P.epsilon),\n    ),\n    :quote => P.token('\"'),\n    :esc => P.token('\\\\'),\n    :string => P.seq(:quote, :instrings => P.many(:instring), :quote),\n    :instring => P.first(\n        :escaped => P.seq(:esc, P.first(:esc, :quote)),\n        :notescaped => P.satisfy(x -> x != '\"' && x != '\\\\'),\n    ),\n    :array => P.seq(P.token('['), P.first(:inarray, P.epsilon), P.token(']')),\n    :sep => P.token(','),\n    :inarray => P.tie(P.seq(P.seq(:json), P.many(:separray => P.seq(:sep, :json)))),\n    :obj => P.seq(P.token('{'), P.first(:inobj, P.epsilon), P.token('}')),\n    :pair => P.seq(:string, P.token(':'), :json),\n    :inobj => P.tie(P.seq(P.seq(:pair), P.many(:sepobj => P.seq(:sep, :pair)))),\n    :json => P.first(:obj, :array, :string, :number, :t, :f, :null),\n);\nnothing #hide","category":"page"},{"location":"json/#Making-the-\"fold\"-function","page":"Example: Parsing JSON","title":"Making the \"fold\" function","text":"","category":"section"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"To manage the folding easily, we keep the fold functions in a data structure with the same order as rules:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"folds = Dict(\n    :t => (v, s) -> true,\n    :f => (v, s) -> false,\n    :null => (v, s) -> nothing,\n    :number => (v, s) -> parse(Float64, v),\n    :quote => (v, s) -> v[1],\n    :esc => (v, s) -> v[1],\n    :escaped => (v, s) -> s[2],\n    :notescaped => (v, s) -> v[1],\n    :string => (v, s) -> String(Char.(s[2])),\n    :instrings => (v, s) -> s,\n    :array => (v, s) -> s[2],\n    :inarray => (v, s) -> s,\n    :separray => (v, s) -> s[2],\n    :obj => (v, s) -> Dict{String,Any}(isnothing(s[2]) ? [] : s[2]),\n    :pair => (v, s) -> (s[1] => s[3]),\n    :sepobj => (v, s) -> s[2],\n    :inobj => (v, s) -> s,\n);\n\ndefault_fold(v, subvals) = isempty(subvals) ? nothing : subvals[1]\n\ng = P.make_grammar([:json], P.flatten(rules, Char));\nnothing #hide","category":"page"},{"location":"json/#Parsing-JSON","page":"Example: Parsing JSON","title":"Parsing JSON","text":"","category":"section"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"Let's parse a simple JSONish string that demonstrates most of the rules:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"input = \"\"\"{\"something\":123,\"other\":false,\"refs\":[1,-2.345,[],{},true,false,null,[1,2,3,\"haha\"],{\"is\\\\\"Finished\\\\\"\":true}]}\"\"\";\n\np = P.parse(g, input);\nnothing #hide","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"From the result we can build a Julia JSON-like structure:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"result = P.traverse_match(\n    p,\n    P.find_match_at!(p, :json, 1),\n    fold = (m, p, s) -> get(folds, m.rule, default_fold)(m.view, s),\n)","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"Detail:","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"result[\"refs\"]","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"","category":"page"},{"location":"json/","page":"Example: Parsing JSON","title":"Example: Parsing JSON","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Data-types","page":"Reference","title":"Data types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PikaParser]\nPages = [\"structs.jl\"]","category":"page"},{"location":"reference/#PikaParser.Clause","page":"Reference","title":"PikaParser.Clause","text":"abstract type Clause{G, T}\n\nAbstract type for all clauses that match a grammar with rule labels of type G that match sequences of tokens of type T.\n\nCurrently implemented clauses:\n\nSatisfy\nScan\nToken\nTokens\nEpsilon\nFail\nEndOfInput\nSeq\nFirst\nNotFollowedBy\nFollowedBy\nSome\nMany\nTie\n\nOften it is better to use convenience functions for rule construction, such as seq or token; see flatten for details.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.EndOfInput","page":"Reference","title":"PikaParser.EndOfInput","text":"struct EndOfInput{G, T} <: PikaParser.Clause{G, T}\n\nMatches at the end of the input.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Epsilon","page":"Reference","title":"PikaParser.Epsilon","text":"struct Epsilon{G, T} <: PikaParser.Clause{G, T}\n\nAn always-succeeding epsilon match.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Fail","page":"Reference","title":"PikaParser.Fail","text":"struct Fail{G, T} <: PikaParser.Clause{G, T}\n\nAn always-failing match.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.First","page":"Reference","title":"PikaParser.First","text":"struct First{G, T} <: PikaParser.Clause{G, T}\n\nMatch the first possibility of several matches. Empty First is equivalent to unconditional failure.\n\nFields\n\nchildren::Vector\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.FollowedBy","page":"Reference","title":"PikaParser.FollowedBy","text":"struct FollowedBy{G, T} <: PikaParser.Clause{G, T}\n\nZero-length match that succeeds if follow does match at the same position.\n\nFields\n\nfollow::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Grammar","page":"Reference","title":"PikaParser.Grammar","text":"struct Grammar{G, T}\n\nA representation of the grammar prepared for parsing.\n\nFields\n\nnames::Vector: Topologically sorted list of rule labels (non-terminals)\nidx::Dict{G, Int64} where G: Mapping of rule labels to their indexes in names\nclauses::Array{PikaParser.Clause{Int64, T}, 1} where T: Clauses of the grammar converted to integer labels (and again sorted topologically)\ncan_match_epsilon::Vector{Bool}: Flags for the rules being able to match on empty string unconditionally\nseed_clauses::Vector{Vector{Int64}}: Which clauses get seeded upon matching of a clause\nterminals::Vector{Int64}: Sorted indexes of terminal clauses that are checked against each input item.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Many","page":"Reference","title":"PikaParser.Many","text":"struct Many{G, T} <: PikaParser.Clause{G, T}\n\nGreedily matches a sequence of matches that can be empty.\n\nFields\n\nitem::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Match","page":"Reference","title":"PikaParser.Match","text":"struct Match\n\nInternal match representation.\n\nFields\n\nclause::Int64: Which clause has matched here?\nfirst::Int64: Where the match started?\nlast::Int64: What is the last item of the match? (In case of empty match, this MUST be the previous index before first, i.e., prevind(input, first).)\noption_idx::Int64: Which possibility (given by the clause) did we match?\nsubmatches::Int64: Index to the first submatch, the range of submatches spans all the way to the first submatch of the next Match.\nleft::Int64: Left child in the memo tree.\nright::Int64: Right child in the memo tree.\nparent::Int64: Parent in the memo tree.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.MatchResult","page":"Reference","title":"PikaParser.MatchResult","text":"primitive type Int64 <: Signed 64\n\nA match index in ParserState field matches, or nothing if the match failed.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.NotFollowedBy","page":"Reference","title":"PikaParser.NotFollowedBy","text":"struct NotFollowedBy{G, T} <: PikaParser.Clause{G, T}\n\nZero-length match that succeeds if reserved does not match at the same position.\n\nFields\n\nreserved::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.ParserState","page":"Reference","title":"PikaParser.ParserState","text":"mutable struct ParserState{G, T, I}\n\nIntermediate parsing state. The match tree is built in a vector of matches that grows during the matching, all match indexes point into this vector.\n\nThis structure is also a \"result\" of the parsing, used to reconstruct the match tree.\n\nFields\n\ngrammar::PikaParser.Grammar: Copy of the grammar used to parse the input.\nq::PikaParser.PikaQueue: Queue for rules that should match, used only internally.\nmatches::Vector{PikaParser.Match}: Matches, connected by indexes to form a memo table search tree.\nmemo_root::Int64: Root of the memotable search tree (stored in the matches).\nsubmatches::Vector{Int64}: Children pointers of the matches that form the match tree.\ninput::Any: Parser input, used to reconstruct match data.\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Satisfy","page":"Reference","title":"PikaParser.Satisfy","text":"struct Satisfy{G, T} <: PikaParser.Terminal{G, T}\n\nA single terminal. Matches a token from the input stream where the match function returns true, otherwise it returns false.\n\nFields\n\nmatch::Function\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Scan","page":"Reference","title":"PikaParser.Scan","text":"struct Scan{G, T} <: PikaParser.Terminal{G, T}\n\nA single terminal, possibly made out of multiple input tokens.\n\nGiven the input stream view, the match function scans the input forward and returns the position of the last item of the matched terminal (which is assumed to start at the beginning of the stream view). In case there's no match, it returns zero.\n\nFields\n\nmatch::Function\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Seq","page":"Reference","title":"PikaParser.Seq","text":"struct Seq{G, T} <: PikaParser.Clause{G, T}\n\nSequence of matches. Empty Seq is equivalent to an always-succeeding empty match, as in Epsilon.\n\nFields\n\nchildren::Vector\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Some","page":"Reference","title":"PikaParser.Some","text":"struct Some{G, T} <: PikaParser.Clause{G, T}\n\nGreedily matches a sequence of matches, with at least 1 match.\n\nFields\n\nitem::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Tie","page":"Reference","title":"PikaParser.Tie","text":"struct Tie{G, T} <: PikaParser.Clause{G, T}\n\nProduces the very same match as the item, but concatenates the user views of the resulting submatches into one big vector (i.e., basically squashing the 2 levels of child matches to a single one.) Useful e.g. for lists with different initial or final elements.\n\nAs a result, the item and its immediate children are not going to be present in the parse tree.\n\nFields\n\ntuple::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Token","page":"Reference","title":"PikaParser.Token","text":"struct Token{G, T} <: PikaParser.Terminal{G, T}\n\nA single token equal to match.\n\nFields\n\ntoken::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.Tokens","page":"Reference","title":"PikaParser.Tokens","text":"struct Tokens{G, T, I} <: PikaParser.Terminal{G, T}\n\nA series of tokens equal to match.\n\nFields\n\ntokens::Any\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.TraverseNode","page":"Reference","title":"PikaParser.TraverseNode","text":"mutable struct TraverseNode{G, S}\n\nPart of intermediate tree traversing state.\n\nFields\n\nparent_idx::Int64\nparent_sub_idx::Int64\nmatch::PikaParser.UserMatch\nopen::Bool\nsubvals::Vector\n\n\n\n\n\n","category":"type"},{"location":"reference/#PikaParser.UserMatch","page":"Reference","title":"PikaParser.UserMatch","text":"struct UserMatch{G, S}\n\nUser-facing representation of a Match.\n\nFields\n\nrule::Any: Which rule ID has matched here?\nfirst::Int64: Where the match started?\nlast::Int64: What is the last item of the match? (In case of empty match, this is the previous index before first.)\nview::Any: View of the matched part of the input, usually a SubArray or SubString.\nsubmatches::Vector{Int64}: Indexes and rule labels of the matched submatches. This forms the edges in the match tree.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Preparing-the-grammar","page":"Reference","title":"Preparing the grammar","text":"","category":"section"},{"location":"reference/#Specifying-rules","page":"Reference","title":"Specifying rules","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PikaParser]\nPages = [\"frontend.jl\"]","category":"page"},{"location":"reference/#PikaParser.end_of_input","page":"Reference","title":"PikaParser.end_of_input","text":"end_of_input :: Clause\n\nAn EndOfInput clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nwhole_file = seq(:file_contents, end_of_input)\n\n\n\n\n\n","category":"constant"},{"location":"reference/#PikaParser.epsilon","page":"Reference","title":"PikaParser.epsilon","text":"epsilon :: Clause\n\nAn Epsilon clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nmaybe_letter_a = first(token('a'), epsilon)\n\n\n\n\n\n","category":"constant"},{"location":"reference/#PikaParser.fail","page":"Reference","title":"PikaParser.fail","text":"fail :: Clause\n\nA Fail clause. Translate to strongly typed grammar with flatten.\n\nUseful for avoiding rule specification when matching terminals using the fast_match parameter of parse.\n\nExample\n\nseq(:this, :that, fail)  # this rule is effectively disabled\n\n\n\n\n\n","category":"constant"},{"location":"reference/#PikaParser.first-Tuple","page":"Reference","title":"PikaParser.first","text":"first(args...) -> PikaParser.First{Any, Any}\n\n\nBuild a First clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nfirst(:something, :fallback, :fallback2)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.flatten-Union{Tuple{G}, Tuple{Dict{G}, DataType}, Tuple{Dict{G}, DataType, Function}} where G","page":"Reference","title":"PikaParser.flatten","text":"flatten(rules::Dict{G}, tokentype::DataType) -> Dict\nflatten(\n    rules::Dict{G},\n    tokentype::DataType,\n    childlabel::Function\n) -> Dict\n\n\nConvert a possibly nested and weakly typed rules into a correctly typed and unnested ruleset, usable in make_grammar. This allows use of convenience rule building functions:\n\nsatisfy\nscan\ntoken\ntokens\nepsilon (not a function!)\nfail (not a function!)\nseq\nfirst\nnot_followed_by\nfollowed_by\nsome\nmany\ntie\nprecedence_cascade (not backed by an actual Clause!)\n\nAnonymous nested rules are assigned names that are constructed by childlabel function (gets the original G and and integer with position integer). By default, childlabel concatenates the parent rule name, hyphen, and the position number to form a Symbol (i.e., the default works only in cases when the rules are labeled by Symbols, and you need to provide your own implementation for other grammars labeled e.g. by integers or strings).\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.followed_by-Tuple{G} where G","page":"Reference","title":"PikaParser.followed_by","text":"followed_by(x) -> PikaParser.FollowedBy{_A, Any} where _A\n\n\nBuild a FollowedBy clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nseq(:digits, followed_by(:whitespace))\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.many-Tuple{G} where G","page":"Reference","title":"PikaParser.many","text":"many(x) -> PikaParser.Many{_A, Any} where _A\n\n\nBuild a Many clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nseq(:quote, many(:quote_contents), :quote)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.not_followed_by-Tuple{G} where G","page":"Reference","title":"PikaParser.not_followed_by","text":"not_followed_by(\n    x\n) -> PikaParser.NotFollowedBy{_A, Any} where _A\n\n\nBuild a NotFollowedBy clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nseq(not_followed_by(tokens(collect(\"reservedWord\"))), :identifier)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.precedence_cascade-Tuple{Function, Vararg{Any}}","page":"Reference","title":"PikaParser.precedence_cascade","text":"precedence_cascade(label::Function, levels...) -> Vector\n\n\nConvert a list of rules of increasing associativity to a typical precedence-handling \"failthrough\" construction. The result must be post-processed by flatten.\n\nEach of the rules is abstracted by \"same-associativity\" and \"higher-associativity\" rules (i.e., it is a binary function), which is used to correctly link the rules within the precedence group. The first rule is of the lowest precedence. All rules except the last automatically fallback to the next rule. The higher-precedence parameter of the last rule is the label of the first rule.\n\nlabel is a function that generates the label for given n-th level of the grammar.\n\nUse @precedences for a less verbose construction.\n\nReturns a vector of labeled rules; that must usually be interpolated into the ruleset.\n\nExample\n\nDict(\n    precedence_cascade(\n        n -> Symbol(:exprlevel, n),\n        (same, next) -> :expr => first(\n            :plus => seq(same, token('+'), next),\n            :minus => seq(same, token('-'), next),\n        ),\n        (same, next) -> :times => seq(same, token('*'), next), # left associative\n        (same, next) -> :power => seq(next, token('^'), same), # right associative\n        (_, restart) -> first(\n            :parens => seq(token('('), restart, token(')')),\n            :digits => some(satisfy(isdigit)),\n        ),\n    )...,\n)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.satisfy-Tuple{Function}","page":"Reference","title":"PikaParser.satisfy","text":"satisfy(f::Function) -> PikaParser.Satisfy{Any, Any}\n\n\nBuild a Satisfy clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nsatisfy(isdigit)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.scan-Tuple{Function}","page":"Reference","title":"PikaParser.scan","text":"scan(f::Function) -> PikaParser.Scan{Any, Any}\n\n\nBuild a Scan clause. Translate to strongly typed grammar with flatten.\n\nExample\n\n# a rule to match any pair of equal tokens\nscan(m -> (length(m) >= 2 && m[1] == m[2]) ? 2 : 0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.seq-Tuple","page":"Reference","title":"PikaParser.seq","text":"seq(args...) -> PikaParser.Seq{Any, Any}\n\n\nBuild a Seq clause. Translate to strongly typed grammar with flatten.\n\nExample\n\ndigit_in_parents = seq(token('('), :digit, token(')'))\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.some-Tuple{G} where G","page":"Reference","title":"PikaParser.some","text":"some(x) -> PikaParser.Some{_A, Any} where _A\n\n\nBuild a Some clause. Translate to strongly typed grammar with flatten.\n\nExample\n\nsome(satisfy(isspace))\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.tie-Tuple{G} where G","page":"Reference","title":"PikaParser.tie","text":"tie(x) -> PikaParser.Tie{_A, Any} where _A\n\n\nBuild a Tie clause. Translate to strongly typed grammar with flatten.\n\nExample\n\n:alternating_A_and_B => tie(many(seq(:A, :B)))\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.token-Tuple{T} where T","page":"Reference","title":"PikaParser.token","text":"token(x) -> PikaParser.Token{Any}\n\n\nBuild a Token clause. Translate to strongly typed grammar with flatten.\n\nExample\n\ntoken('a')\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.tokens-Tuple{I} where I","page":"Reference","title":"PikaParser.tokens","text":"tokens(xs) -> PikaParser.Tokens{Any}\n\n\nBuild a Tokens clause. Translate to strongly typed grammar with flatten.\n\nExample\n\ntokens(\"keyword\")\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.@precedences-Tuple{Any, Symbol, Symbol, Any}","page":"Reference","title":"PikaParser.@precedences","text":"@precedences labeller same::Symbol next::Symbol rules\n\nA shortcut macro for precedence_cascade. Automatically adds lambda heads with fixed argument names, and splats itself with ... into the surrounding environment.\n\nExample\n\nDict(\n    @precedences (n->Symbol(:exprlevel, n)) same next begin\n        :expr => seq(same, token('+'), next)\n        seq(same, token('*'), next)\n        first(\n            token('x'),\n            seq(token('('), next, token(')'))\n        )\n    end\n)\n\n\n\n\n\n","category":"macro"},{"location":"reference/#Converting-to-a-Grammar","page":"Reference","title":"Converting to a Grammar","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PikaParser]\nPages = [\"grammar.jl\"]","category":"page"},{"location":"reference/#PikaParser.make_grammar-Union{Tuple{T}, Tuple{G}, Tuple{AbstractVector{G}, Dict{G, PikaParser.Clause{G, T}}}} where {G, T}","page":"Reference","title":"PikaParser.make_grammar","text":"make_grammar(\n    starts::AbstractArray{G, 1},\n    rules_dict::Dict{G, PikaParser.Clause{G, T}}\n) -> PikaParser.Grammar\n\n\nProduce a Grammar with rules of type G that can be used to parse inputs.\n\nstarts should collect top-level rules (these will be put at the top of the topological order of the parsing).\n\nrules_dict is a dictionary of grammar Clauses.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Parsing","page":"Reference","title":"Parsing","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PikaParser]\nPages = [\"parse.jl\"]","category":"page"},{"location":"reference/#PikaParser.lex-Union{Tuple{I}, Tuple{T}, Tuple{G}, Tuple{PikaParser.Grammar{G, T}, I}} where {G, T, I}","page":"Reference","title":"PikaParser.lex","text":"lex(g::PikaParser.Grammar{G, T}, input) -> Vector\n\n\nGreedily find terminals in the input sequence. For performance and uniqueness purposes, terminals are only looked for at stream indexes that follow the final indexes of terminals found previously. That allows the lexing process to skip many redundant matches that could not ever be found by the grammar.\n\nAs a main outcome, this prevents the typical pika-parser behavior when matching sequences using many, where e.g. an identifier like abcd also produces redundant (and often invalid) matches for bcd, cd and d. Colaterally, greedy lexing also creates less tokens in the match table, which results in faster parsing.\n\nTo produce good terminal matches quickly, use scan.\n\nIn a typical use, this function is best called indirectly via parse_lex.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.parse-Union{Tuple{I}, Tuple{T}, Tuple{G}, Tuple{PikaParser.Grammar{G, T}, I}, Tuple{PikaParser.Grammar{G, T}, I, Any}} where {G, T, I}","page":"Reference","title":"PikaParser.parse","text":"parse(\n    grammar::PikaParser.Grammar{G, T},\n    input\n) -> PikaParser.ParserState\nparse(\n    grammar::PikaParser.Grammar{G, T},\n    input,\n    fast_match\n) -> PikaParser.ParserState\n\n\nTake a Grammar and an indexable input sequence (typically Vector or String), and return a final ParserState that contains all matched grammar productions.\n\nThe input must be random-indexable (because PikaParsers require a lot of random indexing) using Int indexes, must support firstindex, lastindex, prevind, nextind, index arithmetics with + and -, and indexes in views must be the same as in original container except for a constant offset.\n\nLexing and fast terminal matching\n\nIf fast_match is specified, the function does not match terminals using the associated grammar rules, but with a fast_match function that reports the matched terminals via a callback. The function is called exactly once for each position in input in reverse order (i.e., the indexes will start at lastindex(input) and continue using prevind all the way to firstindex(input)), which can be utilized by the application for optimization. The call parameters consist of the input vector, position in the input vector, and a \"report\" function used to send back a clause ID (of same type as G in typeof(grammar)) and the last item of the terminal match that can starts at that position. Calls to the reporting function can be repeated if more terminal types match. Terminals not reported by the calls to fast_match will not be matched.\n\nFor complicated grammars, this may be much faster than having the parser to try matching all terminal types at each position.\n\nIf your grammar does not contain dangerous or highly surprising kinds of terminals (in particular, it can be scanned greedily left-to-right), you may use parse_lex to run a reasonable terminal-only lexing step, which is then automatically used as a basis for fast matching.\n\nCaveats\n\nTake care when indexing Strings. With UTF-8, not all codepoints may necessarily have length 1.\n\nIf unsure, you may always collect the strings to vectors of Chars (basically converting to UTF-32), where each character occupies precisely one index.\n\nResults\n\nUse find_match_at! to extract matches from ParserState.\n\nPika parsing never really fails. Instead, in case when the grammar rule is not matched in the input, the expected rule match match is either not going to be found at the starting position with find_match_at!, or it will not span the whole input.\n\nExample\n\nparse(\n    g,\n    \"abcde123\",\n    (input, i, match) -> isdigit(input[i]) ? match(:digit, i) : match(:letter, i),\n)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.parse_lex-Union{Tuple{I}, Tuple{T}, Tuple{G}, Tuple{PikaParser.Grammar{G, T}, I}} where {G, T, I}","page":"Reference","title":"PikaParser.parse_lex","text":"parse_lex(\n    g::PikaParser.Grammar{G, T},\n    input\n) -> PikaParser.ParserState\n\n\nUse lex to greedily produce lexemes for a given grammar, and run the parsing atop the result.\n\nWhile this will produce a different (much more sparse) parsing table and the resulting parse tree may be different from the \"full\" parse, having the lower levels of the parse tree efficiently pre-chewed vastly simplifies the overall parsing, thus saving a lot of time.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Traversing-and-folding-the-parse-tree","page":"Reference","title":"Traversing and folding the parse tree","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [PikaParser]\nPages = [\"traverse.jl\"]","category":"page"},{"location":"reference/#PikaParser.default_fold-Tuple{Any, Any, Any}","page":"Reference","title":"PikaParser.default_fold","text":"default_fold(m, p, subvals) -> Expr\n\n\nThe default function used as fold argument in traverse_match.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.default_open-Tuple{Any, Any}","page":"Reference","title":"PikaParser.default_open","text":"default_open(\n    m,\n    p\n) -> Base.Generator{_A, PikaParser.var\"#35#36\"} where _A\n\n\nThe default function used as open argument in traverse_match.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.find_match_at!-Union{Tuple{G}, Tuple{PikaParser.ParserState{G}, G, Int64}} where G","page":"Reference","title":"PikaParser.find_match_at!","text":"find_match_at!(\n    st::PikaParser.ParserState{G},\n    rule,\n    pos::Int64\n) -> Int64\n\n\nFind the Match index in ParserState that matched rule at position pos, or nothing if there is no such match.\n\nZero-length matches may not be matched at all positions by default; this function creates the necessary matches in the tables in st in case they are missing. (That is the reason for the ! label.)\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.traverse_match-Union{Tuple{I}, Tuple{G}, Tuple{PikaParser.ParserState{G, I}, Int64}} where {G, I}","page":"Reference","title":"PikaParser.traverse_match","text":"traverse_match(\n    st::PikaParser.ParserState{G, I},\n    mid::Int64;\n    open,\n    fold\n) -> Expr\n\n\nGiven a Match index in ParserState st, recusively depth-first traverse the match tree using functions open (called upon entering a submatch) and fold (called upon leaving the submatch).\n\nopen is given a UserMatch structure and a reference to the parser state. It should return a vector of boolean values that tell the traversal which submatches from the UserMatch should be opened. That can be used to skip parsing of large uninteresting parts of the match tree, such as whitespace or comments. By default, it opens all submatches, thus the whole subtree is traversed.\n\nfold is given the UserMatch structure and a reference to the parser state, and additionally a vector of folded values from the submatches. The values returned by fold invocations are collected and transferred to higher-level invocations of fold. In case open disabled the evaluation of a given submatch, nothing is used as the folded value for the submatch. The default open and fold (default_open, default_fold) just collect all submatch values and produce a Julia Expr AST structure where rule expansions are represented as function calls.\n\nFor producing the UserMatch structures correctly, traverse_match additionally requires that the input vector (stored here in ParserState) has a compatible overload of the standard Base.view.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.view_match-Tuple{PikaParser.ParserState, Int64}","page":"Reference","title":"PikaParser.view_match","text":"view_match(st::PikaParser.ParserState, mid::Int64) -> Any\n\n\nGet a view of input that corresponds to the match identified by given match ID.\n\n\n\n\n\n","category":"method"},{"location":"reference/#PikaParser.view_match-Tuple{PikaParser.ParserState, Union{PikaParser.Match, PikaParser.UserMatch}}","page":"Reference","title":"PikaParser.view_match","text":"view_match(\n    st::PikaParser.ParserState,\n    match::Union{PikaParser.Match, PikaParser.UserMatch}\n) -> Any\n\n\nGet a view of input that corresponds to the given match.\n\n\n\n\n\n","category":"method"},{"location":"#PikaParser.jl","page":"README","title":"PikaParser.jl","text":"","category":"section"},{"location":"","page":"README","title":"README","text":"Modules = [PikaParser]\nPages = [\"PikaParser.jl\"]","category":"page"},{"location":"#PikaParser.PikaParser","page":"README","title":"PikaParser.PikaParser","text":"PikaParser.jl – Parser library for Julia\n\nBuild status Documentation\n(Image: CI status) (Image: codecov) (Image: stable documentation) (Image: dev documentation)\n\nA simple straightforward implementation of PikaParser in pure Julia, following the specification by Luke A. D. Hutchison (see https://github.com/lukehutch/pikaparser).\n\nPika parsers are pretty fast, they are easy to specify, carry the ability to unambiguously match all PEG grammars including the left-recursive ones, and provide great mechanisms for parsing error recovery.\n\nExample\n\nimport PikaParser as P\n\nBuilding a grammar\n\nAll grammar clauses are subtype of a Clause. The types are indexed by the labels for your grammar rules – Julia symbols are a natural choice, but you are free to use integers, strings, or anything else.\n\nrules = Dict(\n    # match a sequence of characters that satisfies `isdigit`\n    :digits => P.some(:digit => P.satisfy(isdigit)),\n\n    # expression in parentheses\n    :parens => P.seq(\n        P.token('('),\n        # you can name the rules in nested contexts\n        :expr => P.first(:plusexpr, :minusexpr, :digits, :parens),\n        P.token(')'),\n    ),\n\n    # some random operators\n    :plusexpr => P.seq(:expr, P.token('+'), :expr),\n    :minusexpr => P.seq(:expr, P.token('-'), :expr),\n)\n\ng = P.make_grammar(\n    [:expr], # the top-level rule\n    P.flatten(rules, Char), # process the rules into a single level and specialize them for crunching Chars\n)\n\nThe grammar is now prepared for parsing.\n\nParsing text\n\nParsing is executed simply by running your grammar on any indexable input using parse.\n\n(Notably, PikaParsers require frequent indexing of inputs, and incremental parsing of streams is thus complicated. To improve the performance, it is also advisable to lex your input into a vector of more complex tokens, using e.g. parse_lex.)\n\ninput = \"12-(34+567-8)\"\np = P.parse(g, input)\n\nYou can find if an expression was matched at a certain position:\n\nP.find_match_at!(p, :expr, 1)\n\n...which returns an index in the match table (if found), such as 45.\n\nYou can have a look at the match: p.matches[45] should return: PikaParser.Match(10, 1, 13, 2, 52, 0, 41, 0) where 10 is the renumbered rule ID for :expr, 1 is the starting position of the match in the input, 13 is the last position of the match (here, that means the whole input); 2 is the option index (in this case, it points to :expr option 2, which is :minusexpr). The rest of the Match structure is used for internal values that organize the match tree and submatches.\n\nRecovering parsed ASTs\n\nYou can use traverse_match to recursively walk the parse trees, to produce ASTs, and translate, interpret or evaluate the expressions:\n\nP.traverse_match(p, P.find_match_at!(p, :expr, 1))\n\nBy default, this runs through the whole match tree and transcodes the matches to Julia Expr AST. In this case, if you pipe the output through JuliaFormatter, you will get something like:\n\nexpr(\n    minusexpr(\n        expr(digits(digit(\"1\"), digit(\"2\"))),\n        var\"minusexpr-2\"(\"-\"),\n        expr(\n            parens(\n                var\"parens-1\"(\"(\"),\n                expr(\n                    plusexpr(\n                        expr(digits(digit(\"3\"), digit(\"4\"))),\n                        var\"plusexpr-2\"(\"+\"),\n                        expr(\n                            minusexpr(\n                                expr(digits(digit(\"5\"), digit(\"6\"), digit(\"7\"))),\n                                var\"minusexpr-2\"(\"-\"),\n                                expr(digits(digit(\"8\"))),\n                            ),\n                        ),\n                    ),\n                ),\n                var\"parens-3\"(\")\"),\n            ),\n        ),\n    ),\n)\n\nIt is straightforward to specify your own method of evaluating the parses by supplying the matchtree opening and folding functions. For example, you can evaluate the expression as follows:\n\nP.traverse_match(p, P.find_match_at!(p, :expr, 1),\n    fold = (m, p, subvals) ->\n        m.rule == :digits ? parse(Int, m.view) :\n        m.rule == :expr ? subvals[1] :\n        m.rule == :parens ? subvals[2] :\n        m.rule == :plusexpr ? subvals[1] + subvals[3] :\n        m.rule == :minusexpr ? subvals[1] - subvals[3] : nothing,\n)\n\nYou should get the expectable result (-581).\n\nAcknowledgements\n\nPikaParser.jl was developed at the Luxembourg Centre for Systems Biomedicine of the University of Luxembourg (uni.lu/lcsb). The development was supported by European Union's Horizon 2020 Programme under PerMedCoE project (permedcoe.eu), agreement no. 951773.\n\n<img src=\"docs/src/assets/unilu.svg\" alt=\"Uni.lu logo\" height=\"64px\">   <img src=\"docs/src/assets/lcsb.svg\" alt=\"LCSB logo\" height=\"64px\">   <img src=\"docs/src/assets/permedcoe.svg\" alt=\"PerMedCoE logo\" height=\"64px\">\n\n\n\n\n\n","category":"module"}]
}
